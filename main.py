import matplotlib.pyplot as plt
import pandas as pd
import os
import time
import numpy as np
from MLProjekt.Dane.data_loader import load_data, get_basic_stats
from MLProjekt.Modele_ML.model_training import train_and_evaluate_models
from MLProjekt.Analiza.visualizations import plot_model_comparison, plot_confusion_matrices, plot_feature_importance, plot_seasonal_accuracy
from MLProjekt.Dane.data_preprocessing import prepare_features, prepare_predictive_features, prepare_predictive_features_sample
from MLProjekt.Analiza.error_analysis import analyze_errors
from sklearn.metrics import accuracy_score
from MLProjekt.Modele_ML.hyperparameter_tuning import optimize_hyperparameters
# Konfiguracja projektu
config = {
    'n_games': 10,          # Ile poprzednich mecz√≥w analizowaƒá
    'use_sample': True,    
    'sample_size': 30000,   
    'sample_method': 'recent',  # Metoda pr√≥bkowania: 'recent', 'random' lub 'season'
    'use_cache': True,    
    'cache_file': 'cached_features.csv',  
    'compare_with_original': True,  
    'save_results': True,   
    'results_dir': 'wyniki'  
}

if config['save_results'] and not os.path.exists(config['results_dir']):
    os.makedirs(config['results_dir'])

data_path = "/home/user/Semestr4/ProjektyS4/MLProjekt/csv/"

if config['use_sample']:
    config['cache_file'] = f"cached_features_{config['sample_method']}_{config['sample_size']}.csv"
else:
    config['cache_file'] = "cached_features_full.csv"

# 2. Dopiero potem utw√≥rz ≈õcie≈ºkƒô
cache_path = os.path.join(os.path.dirname(data_path), config['cache_file'])

print(f"U≈ºywam pliku cache: {cache_path}")
print(f"Plik istnieje: {os.path.exists(cache_path)}")

print("=" * 80)
print("NBA - System Predykcji Wynik√≥w Mecz√≥w")
print("=" * 80)

# Mierzenie czasu wykonania
start_time = time.time()

# ETAP 1: Wczytanie danych 
print("\n[1/8] Wczytywanie danych...")
data = load_data(data_path)

# Podstawowe statystyki
stats = get_basic_stats(data)
print(f"Liczba mecz√≥w: {stats['num_games']}")
print(f"Zakres dat: {stats['date_range'][0]} - {stats['date_range'][1]}")
print(f"Liczba dru≈ºyn: {stats['num_teams']}")
print(f"Procent zwyciƒôstw gospodarzy: {stats['home_advantage']:.2%}")
print(f"Postƒôp: 10% (wczytano dane)")

# ETAP 2: Przygotowanie cech predykcyjnych 
print("\n[2/8] Przygotowywanie cech predykcyjnych...")

# Sprawdzenie czy istnieje plik cache'u
if config['use_cache'] and os.path.exists(cache_path):
    print(f"Wczytywanie cech z cache'u: {cache_path}")
    predictive_features_df = pd.read_csv(cache_path)
    # Konwersja kolumny z datƒÖ 
    if 'game_date' in predictive_features_df.columns:
        predictive_features_df['game_date'] = pd.to_datetime(predictive_features_df['game_date'])
else:
    # Wyb√≥r metody przygotowania cech
    if config['use_sample']:
        print(f"U≈ºywanie pr√≥bki {config['sample_size']} mecz√≥w (metoda: {config['sample_method']})")
        predictive_features_df = prepare_predictive_features_sample(
            data['game'], 
            data['team'],
            sample_size=config['sample_size'], 
            n_games=config['n_games'], 
            sample_method=config['sample_method']
        )
    else:
        print("U≈ºywanie pe≈Çnego zbioru danych (mo≈ºe potrwaƒá d≈Çugo!)")
        predictive_features_df = prepare_predictive_features(
            data['game'], 
            data['team'], 
            n_games=config['n_games']
        )
    if config['use_cache']:
        print(f"Zapisywanie cech do cache'u: {cache_path}")
        predictive_features_df.to_csv(cache_path, index=False)

print(f"WA≈ªNE: Faktycznie wygenerowano {len(predictive_features_df)} mecz√≥w")
print(f"Postƒôp: 30% (przygotowano cechy)")
print("\n[3/8] Wyb√≥r cech i czyszczenie danych...")

# Wyb√≥r cech predykcyjnych
selected_predictive_features = [
    'win_pct_diff', 'fg_pct_diff', 'fg3_pct_diff', 'ft_pct_diff', 
    'reb_diff', 'ast_diff', 'stl_diff', 'blk_diff', 'tov_diff', 'home_adv'
]

# Usuniƒôcie NaN
features_clean = predictive_features_df.dropna(subset=selected_predictive_features)
print(f"Po usuniƒôciu NaN pozosta≈Ço {len(features_clean)} wierszy")

print("\n[4/8] Podzia≈Ç na zbiory treningowy i testowy...")

# Podzia≈Ç na zbiory treningowy i testowy
features_sorted = features_clean.sort_values('game_date')
train_size = int(0.8 * len(features_sorted))
train_data = features_sorted.iloc[:train_size]
test_data = features_sorted.iloc[train_size:]

X_train = train_data[selected_predictive_features]
y_train = train_data['home_win']
X_test = test_data[selected_predictive_features]
y_test = test_data['home_win']

print(f"Zbi√≥r treningowy: {len(X_train)} mecz√≥w")
print(f"Zbi√≥r testowy: {len(X_test)} mecz√≥w")
print(f"Postƒôp: 50% (podzielono dane)")

# ETAP 5: Trenowanie i ewaluacja modeli (70% postƒôpu)
print("\n[5/8] Trenowanie i ewaluacja modeli...")

# Trenowanie i ewaluacja modeli
model_results, predictions, X_train_scaled, X_test_scaled = train_and_evaluate_models(
    X_train, y_train, X_test, y_test
)
print(f"Postƒôp: 60% (wytrenowano modele)")


# Dodaj ten import na poczƒÖtku pliku
from MLProjekt.Modele_ML.decision_tree_analysis import train_decision_tree, plot_decision_tree_visualization, plot_feature_importance_dt, get_decision_rules, analyze_decision_paths, optimize_decision_tree

# Dodaj ten kod po sekcji trenowania modeli:

# ETAP 5.5: Analiza z wykorzystaniem Drzewa Decyzyjnego
print("\n[5.5/8] Szczeg√≥≈Çowa analiza za pomocƒÖ drzewa decyzyjnego...")

# Trenuj drzewo decyzyjne z domy≈õlnƒÖ g≈Çƒôboko≈õciƒÖ
tree_results = train_decision_tree(
    X_train_scaled, y_train, 
    X_test_scaled, y_test, 
    selected_predictive_features
)

# Wizualizuj drzewo
if config['save_results']:
    tree_viz_path = os.path.join(config['results_dir'], 'decision_tree.png')
    importance_path = os.path.join(config['results_dir'], 'dt_feature_importance.png')
else:
    tree_viz_path = None
    importance_path = None

plot_decision_tree_visualization(tree_results, tree_viz_path)
plot_feature_importance_dt(tree_results, importance_path)

# Poka≈º regu≈Çy decyzyjne
print("\nRegu≈Çy decyzyjne wyekstrahowane z drzewa:")
rules_text = get_decision_rules(tree_results)
print(rules_text)

# Analiza ≈õcie≈ºek decyzyjnych dla przyk≈Çadowych mecz√≥w
print("\nAnaliza ≈õcie≈ºek decyzyjnych dla przyk≈Çadowych mecz√≥w:")
analyze_decision_paths(tree_results, X_test_scaled, y_test, n_samples=3)

# Optymalizacja g≈Çƒôboko≈õci drzewa
print("\nOptymalizacja g≈Çƒôboko≈õci drzewa decyzyjnego...")
optimized_tree = optimize_decision_tree(X_train_scaled, y_train, X_test_scaled, y_test, selected_predictive_features)

# Zapisz wykres dok≈Çadno≈õci dla r√≥≈ºnych g≈Çƒôboko≈õci
if config['save_results']:
    accuracy_plot_path = os.path.join(config['results_dir'], 'dt_accuracy_vs_depth.png')
    optimized_tree['accuracy_plot'].savefig(accuracy_plot_path, dpi=300, bbox_inches='tight')
    print(f"Zapisano wykres dok≈Çadno≈õci do {accuracy_plot_path}")

# Dodaj optymalny model drzewa do wynik√≥w og√≥lnych
model_results['Decision Tree (Optimized)'] = {
    'model': optimized_tree['model'],
    'accuracy': optimized_tree['accuracy']
}

print(f"Postƒôp: 60% (przeprowadzono analizƒô drzewa decyzyjnego)")


# ETAP 6: Analiza regu≈Ç asocjacyjnych (70% postƒôpu)
print("\n[6/8] Analiza regu≈Ç asocjacyjnych...")

try:
    from mlxtend.frequent_patterns import apriori, association_rules

    # Przygotowanie danych dla regu≈Ç asocjacyjnych
    print("Przygotowanie danych dla analizy regu≈Ç asocjacyjnych...")
    
    # Dyskretyzacja danych - konwersja zmiennych ciƒÖg≈Çych na kategorialne
    features_for_rules = features_clean.copy()
    
    # Przekszta≈Çƒá cechy ciƒÖg≈Çe na kategorialne
    for feature in selected_predictive_features:
        # Podzia≈Ç na 3 kategorie: niski, ≈õredni, wysoki
        features_for_rules[f"{feature}_cat"] = pd.qcut(
            features_for_rules[feature], 
            q=3, 
            labels=["niski", "≈õredni", "wysoki"],
            duplicates='drop'
        )
    
    # Dodaj informacjƒô o wyniku
    features_for_rules['wynik'] = features_for_rules['home_win'].map({True: 'wygrana_gospodarzy', False: 'wygrana_go≈õci'})
    
    # Przekszta≈Çƒá dane do formatu "koszyka" (one-hot encoding)
    categorical_features = [f"{feat}_cat" for feat in selected_predictive_features] + ['wynik']
    
    # One-hot encoding dla kategorii
    basket_data = pd.get_dummies(features_for_rules[categorical_features])
    
    print("Wyszukiwanie czƒôstych wzorc√≥w...")
    # Znajd≈∫ czƒôste wzorce
    frequent_itemsets = apriori(basket_data, min_support=0.1, use_colnames=True)
    print(f"Znaleziono {len(frequent_itemsets)} czƒôstych wzorc√≥w")
    
    # Generowanie regu≈Ç asocjacyjnych
    if len(frequent_itemsets) > 0:
        print("Generowanie regu≈Ç asocjacyjnych...")
        rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=0.7)
        
        # Filtruj regu≈Çy zwiƒÖzane z wynikiem meczu
        win_rules = rules[rules['consequents'].apply(lambda x: 'wynik_wygrana_gospodarzy' in str(x))]
        loss_rules = rules[rules['consequents'].apply(lambda x: 'wynik_wygrana_go≈õci' in str(x))]
        
        print(f"Znaleziono {len(rules)} regu≈Ç asocjacyjnych")
        print(f"W tym {len(win_rules)} regu≈Ç prowadzƒÖcych do wygranej gospodarzy")
        print(f"I {len(loss_rules)} regu≈Ç prowadzƒÖcych do wygranej go≈õci")
        
        # Poka≈º najlepsze regu≈Çy
        if len(win_rules) > 0:
            print("\nNajlepsze regu≈Çy dla wygranej gospodarzy (wed≈Çug lift):")
            top_win_rules = win_rules.sort_values('lift', ascending=False).head(5)
            for i, (_, rule) in enumerate(top_win_rules.iterrows(), 1):
                antecedents = list(rule['antecedents'])
                consequents = list(rule['consequents'])
                print(f"{i}. {', '.join(str(x) for x in antecedents)} => {', '.join(str(x) for x in consequents)}")
                print(f"   Lift: {rule['lift']:.3f}, Confidence: {rule['confidence']:.3f}, Support: {rule['support']:.3f}")
    else:
        print("Nie znaleziono czƒôstych wzorc√≥w (spr√≥buj zmniejszyƒá min_support)")
        rules = pd.DataFrame()
        
    print(f"Postƒôp: 70% (przeprowadzono analizƒô regu≈Ç asocjacyjnych)")
    
except ImportError:
    print("Nie znaleziono pakietu mlxtend - pomijam analizƒô regu≈Ç asocjacyjnych")
    print("Aby zainstalowaƒá: pip install mlxtend")
    rules = pd.DataFrame()
# ETAP 7: Wizualizacje i analiza wynik√≥w
print("\n[7/8] Tworzenie wizualizacji i analiza wynik√≥w...")
if config['save_results']:
    output_path = os.path.join(config['results_dir'], 'model_comparison_predictive.png')
else:
    output_path = None

plot_model_comparison(model_results, output_path)


if config['save_results']:
    output_path = os.path.join(config['results_dir'], 'confusion_matrices.png')
else:
    output_path = None

plot_confusion_matrices(model_results, y_test, predictions, output_path)


# Analiza wa≈ºno≈õci cech
best_model_name = max(model_results.items(), key=lambda x: x[1]['accuracy'])[0]

best_model = model_results[best_model_name]['model']

if best_model_name in ['Random Forest', 'Gradient Boosting']:
    if config['save_results']:
        output_path = os.path.join(config['results_dir'], 'feature_importance.png')
    else:
        output_path = None
    
    plot_feature_importance(
        selected_predictive_features, 
        best_model.feature_importances_,
        best_model_name,
        output_path
    )

if 'game_date' in features_clean.columns:
    features_clean['season'] = pd.to_datetime(features_clean['game_date']).dt.year
    seasons = features_clean['season'].unique()
    
    # S≈Çownik do przechowywania dok≈Çadno≈õci dla ka≈ºdego sezonu
    seasonal_results = {}
    
    print("\nAnaliza sezonowa:")
    for season in seasons:
        season_data = features_clean[features_clean['season'] == season]
        
        if len(season_data) < 50:  # Pomi≈Ñ sezony z ma≈ÇƒÖ liczbƒÖ mecz√≥w
            continue
            
    
        season_train_size = int(0.8 * len(season_data))
        season_train = season_data.iloc[:season_train_size]
        season_test = season_data.iloc[season_train_size:]
        
        if len(season_test) < 10:  # Pomi≈Ñ je≈õli zbyt ma≈Çy zbi√≥r testowy
            continue
            
        X_season_train = season_train[selected_predictive_features]
        y_season_train = season_train['home_win']
        X_season_test = season_test[selected_predictive_features]
        y_season_test = season_test['home_win']
        
        # U≈ºyj najlepszego modelu
        best_model.fit(X_season_train, y_season_train)
        y_season_pred = best_model.predict(X_season_test)
        season_accuracy = (y_season_pred == y_season_test).mean()
        
        seasonal_results[season] = season_accuracy
        print(f"  Sezon {season}: dok≈Çadno≈õƒá = {season_accuracy:.4f} (liczba mecz√≥w: {len(season_data)})")
    
    # Wizualizacja wynik√≥w sezonowych
    if len(seasonal_results) > 1:
        if config['save_results']:
            output_path = os.path.join(config['results_dir'], 'seasonal_accuracy.png')
        else:
            output_path = None
        plot_seasonal_accuracy(seasonal_results, output_path)

# ETAP 7.5: Optymalizacja hiperparametr√≥w
print("\n[7.5/8] Optymalizacja hiperparametr√≥w najlepszego modelu...")

try:
    from MLProjekt.Modele_ML.hyperparameter_tuning import optimize_hyperparameters
    
    
    print(f"Optymalizacja hiperparametr√≥w dla modelu {best_model_name}...")
    best_tuned_model, best_params, best_cv_score = optimize_hyperparameters(
        best_model_name, model_results[best_model_name]['model'], 
        X_train_scaled, y_train, cv=5
    )

    # Test zoptymalizowanego modelu
    y_pred_tuned = best_tuned_model.predict(X_test_scaled)
    tuned_accuracy = accuracy_score(y_test, y_pred_tuned)

    print(f"Dok≈Çadno≈õƒá modelu przed strojeniem: {model_results[best_model_name]['accuracy']:.4f}")
    print(f"Dok≈Çadno≈õƒá modelu po strojeniu: {tuned_accuracy:.4f}")
    
    # ZastƒÖp najlepszy model zoptymalizowanym modelem
    model_results[best_model_name]['model'] = best_tuned_model
    model_results[best_model_name]['accuracy'] = tuned_accuracy
    predictions[best_model_name] = y_pred_tuned
    
    print(f"Postƒôp: 92% (zoptymalizowano hiperparametry)")

except ImportError:
    print("Nie znaleziono modu≈Çu hyperparameter_tuning - pomijam optymalizacjƒô hiperparametr√≥w")
    print(f"Postƒôp: 92% (pominiƒôto optymalizacjƒô hiperparametr√≥w)")

# ETAP 7.6: Analiza b≈Çƒôd√≥w modelu
print("\n[7.6/8] Analiza b≈Çƒôd√≥w modelu...")

try:
    from MLProjekt.Analiza.error_analysis import analyze_errors
    
    # Analiza b≈Çƒôd√≥w najlepszego modelu
    if config['save_results']:
        output_path = os.path.join(config['results_dir'], 'error_analysis.png')
    else:
        output_path = None
    
   
    fig, error_df = analyze_errors(
        X_test_scaled, y_test, predictions[best_model_name], selected_predictive_features
    )
    
    # Zapisz wykres
    if output_path:
        fig.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"Wykres analizy b≈Çƒôd√≥w zapisano jako {output_path}")
    
    # Poka≈º kilka przypadk√≥w b≈Çƒôdnej klasyfikacji
    if len(error_df) > 0:
        print("\nPrzyk≈Çady b≈Çƒôdnych klasyfikacji:")
        for i, (_, row) in enumerate(error_df.head(5).iterrows()):
            print(f"Przypadek {i+1}:")
            for feature in selected_predictive_features:
                print(f"  {feature}: {row[feature]:.4f}")
            print(f"  Rzeczywisty wynik: {'Wygrana' if row['actual'] else 'Pora≈ºka'}")
            print(f"  Przewidywany wynik: {'Wygrana' if row['predicted'] else 'Pora≈ºka'}\n")
    
    print(f"Postƒôp: 95% (przeprowadzono analizƒô b≈Çƒôd√≥w)")

except ImportError:
    print("Nie znaleziono modu≈Çu error_analysis - pomijam analizƒô b≈Çƒôd√≥w")
    print(f"Postƒôp: 95% (pominiƒôto analizƒô b≈Çƒôd√≥w)")

# ETAP 7.7: Krzywa uczenia
print("\n[7.7/8] Generowanie krzywej uczenia...")

try:
    from MLProjekt.Analiza.visualizations import plot_learning_curves
    
    # Generowanie krzywej uczenia dla najlepszego modelu
    if config['save_results']:
        output_path = os.path.join(config['results_dir'], 'learning_curve.png')
    else:
        output_path = None
    
    # Wygeneruj krzywƒÖ uczenia
    plot_learning_curves(
        model_results[best_model_name]['model'],
        X_train_scaled, y_train,
        cv=5,
        output_path=output_path
    )
    
    if output_path:
        print(f"Wykres krzywej uczenia zapisano jako {output_path}")
    
    print(f"Postƒôp: 98% (wygenerowano krzywƒÖ uczenia)")

except Exception as e:
    print(f"B≈ÇƒÖd przy generowaniu krzywej uczenia: {e}")
    print(f"Postƒôp: 98% (pominiƒôto krzywƒÖ uczenia)")
# ETAP 8: Por√≥wnanie z oryginalnym modelem i podsumowanie (100% postƒôpu)


print("\n" + "="*60)
print("üèÄ ETAP 8: ANALIZA REGU≈Å ASOCJACYJNYCH")
print("="*60)
    
from MLProjekt.Analiza.association_rules import run_association_analysis
success = run_association_analysis(features_clean, config['results_dir'])
    
if success:
    print("‚úÖ Analiza regu≈Ç asocjacyjnych zako≈Ñczona!")
else:
    print("‚ùå B≈ÇƒÖd w analizie regu≈Ç asocjacyjnych")
print("\n[8/8] Por√≥wnanie modeli i podsumowanie...")

# Por√≥wnanie z oryginalnym modelem (opcjonalnie)
if config['compare_with_original']:
    print("\nPor√≥wnanie z oryginalnym podej≈õciem (u≈ºywajƒÖcym statystyk z meczu)...")
    original_features_df = prepare_features(data['game'], data['other_stats'])
    original_selected_features = [
        'fg_pct_diff', 'fg3_pct_diff', 'ft_pct_diff', 
        'reb_diff', 'ast_diff', 'stl_diff', 'blk_diff', 'tov_diff', 'pf_diff'
    ]
    original_clean = original_features_df.dropna(subset=original_selected_features)
    print(f"Dane oryginalne po usuniƒôciu NaN: {len(original_clean)} wierszy")
    
    # Podzia≈Ç na zbiory treningowy i testowy
    original_sorted = original_clean.sort_values('game_date')
    train_size = int(0.8 * len(original_sorted))
    original_train_data = original_sorted.iloc[:train_size]
    original_test_data = original_sorted.iloc[train_size:]
    
    X_train_original = original_train_data[original_selected_features]
    y_train_original = original_train_data['home_win']
    X_test_original = original_test_data[original_selected_features]
    y_test_original = original_test_data['home_win']
    
    print(f"Zbi√≥r treningowy (oryginalny): {len(X_train_original)} mecz√≥w")
    print(f"Zbi√≥r testowy (oryginalny): {len(X_test_original)} mecz√≥w")
    
    # Trenowanie i ewaluacja modeli na oryginalnych cechach
    original_results, original_predictions, _, _ = train_and_evaluate_models(
        X_train_original, y_train_original, X_test_original, y_test_original
    )
    
    # Por√≥wnanie najlepszych wynik√≥w
    best_predictive = max(model_results.items(), key=lambda x: x[1]['accuracy'])
    best_original = max(original_results.items(), key=lambda x: x[1]['accuracy'])
    
    print("\nPodsumowanie por√≥wnania:")
    print(f"Najlepszy model predykcyjny: {best_predictive[0]} - dok≈Çadno≈õƒá: {best_predictive[1]['accuracy']:.4f}")
    print(f"Najlepszy model oryginalny: {best_original[0]} - dok≈Çadno≈õƒá: {best_original[1]['accuracy']:.4f}")
    
    # Zapisz podsumowanie do pliku
    if config['save_results']:
        with open(os.path.join(config['results_dir'], 'podsumowanie.txt'), 'w') as f:
            f.write("PODSUMOWANIE EKSPERYMENTU\n\n")
            f.write(f"Liczba analizowanych mecz√≥w: {len(features_clean)}\n")
            f.write(f"Liczba cech predykcyjnych: {len(selected_predictive_features)}\n\n")
            
            f.write("Wyniki modelu predykcyjnego (u≈ºywajƒÖcego statystyk historycznych):\n")
            for name, result in model_results.items():
                f.write(f"- {name}: dok≈Çadno≈õƒá = {result['accuracy']:.4f}\n")
            
            f.write("\nWyniki modelu oryginalnego (u≈ºywajƒÖcego statystyk z meczu):\n")
            for name, result in original_results.items():
                f.write(f"- {name}: dok≈Çadno≈õƒá = {result['accuracy']:.4f}\n")
            
            f.write(f"\nNajlepszy model predykcyjny: {best_predictive[0]} - dok≈Çadno≈õƒá: {best_predictive[1]['accuracy']:.4f}\n")
            f.write(f"Najlepszy model oryginalny: {best_original[0]} - dok≈Çadno≈õƒá: {best_original[1]['accuracy']:.4f}\n")
            
            # Dodaj informacje o regu≈Çach asocjacyjnych
            if len(rules) > 0:
                f.write("\n\nANALIZA REGU≈Å ASOCJACYJNYCH\n\n")
                f.write(f"Znaleziono {len(rules)} regu≈Ç asocjacyjnych.\n\n")
                
                # Sortuj wed≈Çug lift
                top_rules_df = rules.sort_values('lift', ascending=False).head(10)
                f.write("Top 10 regu≈Ç asocjacyjnych wed≈Çug lift:\n")
                for i, (_, rule) in enumerate(top_rules_df.iterrows(), 1):
                    antecedents = list(rule['antecedents'])
                    consequents = list(rule['consequents'])
                    f.write(f"{i}. {antecedents} => {consequents}\n")
                    f.write(f"   Lift: {rule['lift']:.3f}, Confidence: {rule['confidence']:.3f}, Support: {rule['support']:.3f}\n")

# Zapisz model
if config['save_results'] and best_model_name in model_results:
    try:
        import joblib
        best_model = model_results[best_model_name]['model']
        model_path = os.path.join(config['results_dir'], f'best_model_{best_model_name.replace(" ", "_")}.pkl')
        joblib.dump(best_model, model_path)
        print(f"\nZapisano najlepszy model ({best_model_name}) do {model_path}")
    except ImportError:
        print("\nBrak pakietu joblib - nie zapisano modelu")
        print("Aby zainstalowaƒá: pip install joblib")

# Czas wykonania
end_time = time.time()
execution_time = end_time - start_time
print(f"\nCzas wykonania: {execution_time:.2f} sekund ({execution_time/60:.2f} minut)")
print(f"Postƒôp: 100% (zako≈Ñczono)")
print("\nAnaliza wynik√≥w NBA zako≈Ñczona pomy≈õlnie!")


